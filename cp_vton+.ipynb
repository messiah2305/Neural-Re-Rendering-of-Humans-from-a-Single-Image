{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cp_vton+.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyON2xMLRr67ViiR3RT/njVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/messiah2305/Neural-Re-Rendering-of-Humans-from-a-Single-Image/blob/master/cp_vton%2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgY2qCqhtu0n",
        "outputId": "8694ef8f-871e-499a-b753-a8033318c831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cp-vton-plus'...\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 245 (delta 52), reused 10 (delta 3), pack-reused 154\u001b[K\n",
            "Receiving objects: 100% (245/245), 419.58 KiB | 789.00 KiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/minar09/cp-vton-plus.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd cp-vton-plus "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWLZfJ6AIDBD",
        "outputId": "a37d667f-9c14-4483-8127-dcbc9d1eec5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cp-vton-plus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-ZHV4FaIMcE",
        "outputId": "ea86f76d-e74d-4f2a-943f-572091a9dd5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==0.4.1 (from versions: 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch==0.4.1\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZPdYg2qJ1fT",
        "outputId": "e17b5238-21c7-4d2e-b273-2ccb0d06e18a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://1drv.ms/u/s!Ai8t8GAHdzVUiQQYX0azYhqIDPP6?e=4cpFTI "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGBFG2rXMsT6",
        "outputId": "3d6aa4c5-42dc-42e5-9354-38767e78324d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-07 05:35:27--  https://1drv.ms/u/s!Ai8t8GAHdzVUiQQYX0azYhqIDPP6?e=4cpFTI\n",
            "Resolving 1drv.ms (1drv.ms)... 13.107.42.12\n",
            "Connecting to 1drv.ms (1drv.ms)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://onedrive.live.com/redir?resid=5435770760F02D2F!1156&authkey=!ABhfRrNiGogM8_o&e=4cpFTI [following]\n",
            "--2022-04-07 05:35:28--  https://onedrive.live.com/redir?resid=5435770760F02D2F!1156&authkey=!ABhfRrNiGogM8_o&e=4cpFTI\n",
            "Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n",
            "Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6804 (6.6K) [text/html]\n",
            "Saving to: ‘s!Ai8t8GAHdzVUiQQYX0azYhqIDPP6?e=4cpFTI’\n",
            "\n",
            "s!Ai8t8GAHdzVUiQQYX 100%[===================>]   6.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-07 05:35:28 (41.6 MB/s) - ‘s!Ai8t8GAHdzVUiQQYX0azYhqIDPP6?e=4cpFTI’ saved [6804/6804]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/cp-vton-plus/data/dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFaDa9QYilgC",
        "outputId": "407638e7-1dd7-4f0a-e4bd-27237b65d35a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/cp-vton-plus/data/dataset.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/cp-vton-plus/data/dataset.zip or\n",
            "        /content/cp-vton-plus/data/dataset.zip.zip, and cannot find /content/cp-vton-plus/data/dataset.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --name GMM --stage GMM --workers 4 --datamode test --data_list test_pairs.txt --checkpoint checkpoints/GMM/gmm_final.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjNKCqP8It6h",
        "outputId": "40f10a2a-c5c8-40c5-c241-40d7e188073e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=4, checkpoint='checkpoints/GMM/gmm_final.pth', data_list='test_pairs.txt', datamode='test', dataroot='data', display_count=1, fine_height=256, fine_width=192, gpu_ids='', grid_size=5, name='GMM', radius=5, result_dir='result', shuffle=False, stage='GMM', tensorboard_dir='tensorboard', workers=4)\n",
            "Start to test stage: GMM, named: GMM!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "initialization method [normal]\n",
            "initialization method [normal]\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 226, in <module>\n",
            "    main()\n",
            "  File \"test.py\", line 212, in main\n",
            "    test_gmm(opt, test_loader, model, board)\n",
            "  File \"test.py\", line 84, in test_gmm\n",
            "    for step, inputs in enumerate(test_loader.data_loader):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/cp-vton-plus/cp_dataset.py\", line 53, in __getitem__\n",
            "    c = Image.open(osp.join(self.data_path, 'cloth', c_name))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2843, in open\n",
            "    fp = builtins.open(filename, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'data/test/cloth/004508_1.jpg'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uJP6C2ggJt6y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}